# Overview

| Developed by | Guardrails AI |
| --- | --- |
| Date of development | Feb 15, 2024 |
| Validator type | Format |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

# Description

This validator ensures that any URL generated by an LLM is an endpoint that can be reached. In order to validate this, the validator makes a request to the URL and expects a 200 response.

# Installation

```bash
$ guardrails hub install hub://guardrails/endpoint_is_reachable
```

# Usage Examples

## Validating string output via Python

In this example, we apply the validator to a string URL generated by an LLM.

```python
# Import Guard and Validator
from guardrails.hub import EndpointIsReachable
from guardrails import Guard

# Initialize Validator
val = EndpointIsReachable(on_fail="noop")

# Setup Guard
guard = Guard.from_string(
    validators=[val, ...],
)

guard.parse("https://www.guardrailsai.com/")  # Validator passes
guard.parse("https://www.guardrailsai.co/")  # Validator fails
```

## Validating JSON output via Python

In this example, we apply the validator to a URL that is a field within a Pydantic object.

```python
# Import Guard and Validator
from pydantic import BaseModel
from guardrails.hub import EndpointIsReachable
from guardrails import Guard

val = EndpointIsReachable(on_fail="noop")

# Create Pydantic BaseModel
class PaperCitations(BaseModel):
		paper_name: str
		paper_url: str = Field(
				description="URL at which to find paper", validators=[val]
		)

# Create a Guard to check for valid Pydantic output
guard = Guard.from_pydantic(output_class=PetInfo)

# Run LLM output generating JSON through guard
guard.parse("""
{
		"paper_name": "Attention Is All You Need",
		"paper_url": "https://arxiv.org/abs/1706.03762"
}
""")
```

# API Reference

`__init__`

- `on_fail`: The policy to enact when a validator fails.
